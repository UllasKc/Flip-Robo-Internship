{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium WEB SCRAPING ASSIGNMENT-2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name,experience_required. You have to scrape first 10 jobs data.\n",
    "\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore”\n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question1(url):\n",
    "    \n",
    "    #activate chrome browser\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    \n",
    "    \n",
    "    driver.get(url)  #making request\n",
    "    \n",
    "    df_naukri = pd.DataFrame({})   #creating a empty dataframe\n",
    "    \n",
    "    \n",
    "    time.sleep(5)\n",
    "    #finding the element for Designation search bar\n",
    "    designation_search = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "    #write on search bar\n",
    "    #asking for user input\n",
    "    #Designation = input('Enter the Designation you want to search : ')\n",
    "    designation_search.send_keys(\"Data Analyst\") #user input as data analyst\n",
    "    \n",
    "    time.sleep(2)\n",
    "    #finding the element for Location search bar\n",
    "    loaction_search = driver.find_element_by_id('qsb-location-sugg')\n",
    "    #write on search bar\n",
    "    #Location = input('Enter the Location you want to search :')\n",
    "    loaction_search.send_keys('Banglore')  #uesr input as banglore\n",
    "    \n",
    "    time.sleep(2)\n",
    "    #do click using xpath function\n",
    "    search_button = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "    search_button.click()   #clicking the  search button\n",
    "    \n",
    "    time.sleep(5)  #sleep for 4 seconds\n",
    "    \n",
    "    #so extarct all the tags having job-titles\n",
    "    title_tags = driver.find_elements_by_xpath(\"//a[@class= 'title fw500 ellipsis']\")\n",
    "    job_title_list = []   #creating a empty list\n",
    "    for i in title_tags[:10]:  #we only need 10 elements\n",
    "        job_title_list.append(i.text)   #appending it to the list\n",
    "    \n",
    "    #lets get all the company name\n",
    "    company_tags = driver.find_elements_by_xpath(\"//a[@class = 'subTitle ellipsis fleft']\")\n",
    "    company_list = []\n",
    "    for i in company_tags[:10]:\n",
    "        company_list.append(i.text)\n",
    "        \n",
    "    #lets extract the experice\n",
    "    #some data is missin in span tags, lets use parent tag li\n",
    "    experience_tags = driver.find_elements_by_xpath(\"//li[@class = 'fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "    experience_list = []\n",
    "    for i in experience_tags[:10]:\n",
    "        experience_list.append(i.text)\n",
    "    \n",
    "    #lets extract the loaction\n",
    "    #some data is missin in span tags, lets use parent tag li\n",
    "    location_tags = driver.find_elements_by_xpath(\"//li[@class = 'fleft grey-text br2 placeHolderLi location']//span\")\n",
    "    location_list = []\n",
    "    for i in location_tags[:10]:\n",
    "        location_list.append(i.text)\n",
    "\n",
    "    \n",
    "    \n",
    "    df_naukri['Job Title'] = job_title_list  #Creating a column for the particular list\n",
    "    df_naukri['Company'] = company_list\n",
    "    df_naukri['Experience'] = experience_list\n",
    "    df_naukri['Location'] = location_list\n",
    "    \n",
    " \n",
    "    return df_naukri  #returning the Dataframe as result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hiring Data Analysts For E commerce Platform |...</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Hiring For Data Analyst/ MIS Reporting Analyst...</td>\n",
       "      <td>PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>DA - Urgent Opening For Data Analyst BFSI Doma...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Data Analyst - Informatica MDM</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Assistant Vice President - MIS &amp; Reporting ( B...</td>\n",
       "      <td>INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...</td>\n",
       "      <td>12-18 Yrs</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                                       Data Analyst   \n",
       "2  Hiring Data Analysts For E commerce Platform |...   \n",
       "3                                       Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5  Hiring For Data Analyst/ MIS Reporting Analyst...   \n",
       "6  DA - Urgent Opening For Data Analyst BFSI Doma...   \n",
       "7                     Data Analyst - Informatica MDM   \n",
       "8                                       Data Analyst   \n",
       "9  Assistant Vice President - MIS & Reporting ( B...   \n",
       "\n",
       "                                             Company Experience  \\\n",
       "0                 Inflexion Analytix Private Limited    0-3 Yrs   \n",
       "1            GlaxoSmithKline Pharmaceuticals Limited    0-2 Yrs   \n",
       "2                   Allegis Services India Pvt. Ltd.    0-5 Yrs   \n",
       "3                Shell India Markets Private Limited    5-8 Yrs   \n",
       "4                                  Applied Materials   7-10 Yrs   \n",
       "5   PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd    2-4 Yrs   \n",
       "6                     Tata Consultancy Services Ltd.    4-9 Yrs   \n",
       "7                Shell India Markets Private Limited    6-9 Yrs   \n",
       "8                Shell India Markets Private Limited    5-8 Yrs   \n",
       "9  INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...  12-18 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "1                                Bangalore/Bengaluru  \n",
       "2                                Bangalore/Bengaluru  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9                        Mumbai, Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the function to display the dataframe as result\n",
    "question1('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question2(url):\n",
    "    #activate chrome browser\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    driver.get(url)  #making request\n",
    "    \n",
    "    time.sleep(5)\n",
    "    #finding the element for Designation search bar\n",
    "    designation_search = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "    #write on search bar\n",
    "    #asking for user input\n",
    "    #Designation = input('Enter the Designation you want to search : ')\n",
    "    designation_search.send_keys(\"Data Scientist\") #user input as data analyst\n",
    "\n",
    "    time.sleep(2)\n",
    "    #finding the element for Location search bar\n",
    "    loaction_search = driver.find_element_by_id('qsb-location-sugg')\n",
    "    #write on search bar\n",
    "    #Location = input('Enter the Location you want to search :')\n",
    "    loaction_search.send_keys('Banglore')  #uesr input as banglore\n",
    "\n",
    "    time.sleep(2)\n",
    "    #do click using xpath function\n",
    "    search_button = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "    search_button.click()   #clicking the  search button\n",
    "    \n",
    "    \n",
    "    job_links = []  \n",
    "    time.sleep(6)\n",
    "    j_link =driver.find_elements_by_xpath(\"//a[@class ='title fw500 ellipsis']\") #getting all links \n",
    "    for i in j_link:\n",
    "        job_links.append(i.get_attribute('href')) #appendig the links after filtering data scientist and banglore\n",
    "        \n",
    "    j_title = [] #creating empty list\n",
    "    c_name = []\n",
    "    experience_list = []\n",
    "    j_description = []\n",
    "\n",
    "    \n",
    "    #there are some non naukri pages after clicking , for example IBM\n",
    "    #IBM page are having diffrent tags and classes\n",
    "    #so to skip them i used expection handling\n",
    "    \n",
    "    naukri_page_count = 0  #after reaching 10, we will break out of loop\n",
    "    not_naukri_page = 0   #just for cross checking\n",
    "    for j in job_links:  #looping all links\n",
    "        try:\n",
    "            driver.get(j)\n",
    "            time.sleep(4)\n",
    "            naukri_page = driver.find_element_by_id('smjltButton')  #finding some elemet on naukri page\n",
    "        except NoSuchElementException:\n",
    "            not_naukri_page += 1    #if elemet is not found, then it is not a naukri page\n",
    "        else:\n",
    "            #job title\n",
    "            job_title = driver.find_element_by_xpath(\"//h1[@class= 'jd-header-title']\")\n",
    "            j_title.append(job_title.text)   \n",
    "            \n",
    "            #copamny name\n",
    "            company_name  = driver.find_element_by_xpath(\"//div[@class= 'jd-header-comp-name']/a\")\n",
    "            c_name.append(company_name.text)\n",
    "            \n",
    "            #experience required\n",
    "            experience = driver.find_element_by_xpath(\"//div[@class= 'exp']/span\")\n",
    "            experience_list.append(experience.text)\n",
    "            \n",
    "            #full description\n",
    "            full_description = driver.find_element_by_xpath(\"//section[@class= 'job-desc']\")\n",
    "            j_description.append(full_description.text)\n",
    "\n",
    "            #increasing count\n",
    "            naukri_page_count += 1\n",
    "\n",
    "            if naukri_page_count == 10:  #if information is retrived for 10 pages, break the loop\n",
    "                break\n",
    "    \n",
    "    naukri_job_desc_df = pd.DataFrame({})    #creating a empty dataframe\n",
    "    \n",
    "    naukri_job_desc_df['Job Title'] = j_title   #Creating a column for the particular list\n",
    "    naukri_job_desc_df['Comapany'] =c_name\n",
    "    naukri_job_desc_df['Experience required'] =experience_list\n",
    "    naukri_job_desc_df['Full decription'] =j_description\n",
    "    \n",
    "    #theses are some non naukri pages count\n",
    "    print('we found {} not naukri page while scraping, so skipped those pages'.format(not_naukri_page))\n",
    "    \n",
    "    return naukri_job_desc_df   #returning the Dataframe as result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we found 6 not naukri page while scraping, so skipped those pages\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Comapany</th>\n",
       "      <th>Experience required</th>\n",
       "      <th>Full decription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0 - 3 years</td>\n",
       "      <td>Job description\\nJob Role : Data Scientist/Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>2 - 7 years</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>2 - 7 years</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Vijaya Management Services</td>\n",
       "      <td>5 - 10 years</td>\n",
       "      <td>Job description\\n.\\nRoles and Responsibilities...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Senior Data Scientist, Modeling</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>3 - 7 years</td>\n",
       "      <td>Job description\\nWe wont say we can predict th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Senior Data Scientist - Credit risk</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>5 - 10 years</td>\n",
       "      <td>Job description\\n\\nResponsibilities and duties...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>SDE Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>5 - 8 years</td>\n",
       "      <td>Job description\\nBusiness &amp; Team overview:\\nFo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Computational Design Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>5 - 8 years</td>\n",
       "      <td>Job description\\nBusiness &amp; Team overview:\\nFo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Intel Technology India Pvt Ltd</td>\n",
       "      <td>6 - 10 years</td>\n",
       "      <td>Job description\\n\\n\\nWe are seeking an outstan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Senior Data Scientist - Chatbot &amp; NLP</td>\n",
       "      <td>Gojek Tech</td>\n",
       "      <td>3 - 7 years</td>\n",
       "      <td>Job description\\nWhat You Will Do\\nWork with D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "2  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "3                              Senior Data Scientist   \n",
       "4                    Senior Data Scientist, Modeling   \n",
       "5                Senior Data Scientist - Credit risk   \n",
       "6                         SDE Lead Data Scientist-L3   \n",
       "7        Computational Design Lead Data Scientist-L3   \n",
       "8                                Lead Data Scientist   \n",
       "9              Senior Data Scientist - Chatbot & NLP   \n",
       "\n",
       "                             Comapany Experience required  \\\n",
       "0  Inflexion Analytix Private Limited         0 - 3 years   \n",
       "1                            CES Ltd.         2 - 7 years   \n",
       "2                            CES Ltd.         2 - 7 years   \n",
       "3          Vijaya Management Services        5 - 10 years   \n",
       "4                             Nielsen         3 - 7 years   \n",
       "5                  Scienaptic Systems        5 - 10 years   \n",
       "6   Huawei Technologies India Pvt Ltd         5 - 8 years   \n",
       "7   Huawei Technologies India Pvt Ltd         5 - 8 years   \n",
       "8      Intel Technology India Pvt Ltd        6 - 10 years   \n",
       "9                          Gojek Tech         3 - 7 years   \n",
       "\n",
       "                                     Full decription  \n",
       "0  Job description\\nJob Role : Data Scientist/Dat...  \n",
       "1  Job description\\nRoles and Responsibilities\\n\\...  \n",
       "2  Job description\\nRoles and Responsibilities\\n\\...  \n",
       "3  Job description\\n.\\nRoles and Responsibilities...  \n",
       "4  Job description\\nWe wont say we can predict th...  \n",
       "5  Job description\\n\\nResponsibilities and duties...  \n",
       "6  Job description\\nBusiness & Team overview:\\nFo...  \n",
       "7  Job description\\nBusiness & Team overview:\\nFo...  \n",
       "8  Job description\\n\\n\\nWe are seeking an outstan...  \n",
       "9  Job description\\nWhat You Will Do\\nWork with D...  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the function to display the dataframe as result\n",
    "question2('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on thewebpage as shown below:\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field \n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done\n",
    "manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question3(url):\n",
    "    \n",
    "    #activate chrome browser\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    \n",
    "    \n",
    "    driver.get(url)  #making request\n",
    "    \n",
    "    df_naukri = pd.DataFrame({})   #creating a empty dataframe\n",
    "    \n",
    "    time.sleep(3)\n",
    "    #finding the element for Designation search bar\n",
    "    designation_search = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "    #write on search bar\n",
    "    #asking for user input\n",
    "    #Designation = input('Enter the Designation you want to search : ')\n",
    "    designation_search.send_keys(\"Data Scientist\") #user input as data analyst\n",
    "    \n",
    "    \n",
    "    #do click using xpath function\n",
    "    search_button = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "    search_button.click()   #clicking the  search button\n",
    "    \n",
    "    time.sleep(4)  #sleep for 4 seconds\n",
    "    \n",
    "    #adding Filter for Loaction Delhi/NCR\n",
    "    loc_filter = driver.find_element_by_xpath('html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/i')\n",
    "    loc_filter.click()\n",
    "    time.sleep(4)\n",
    "    \n",
    "    #adding filter for salary (3-6 lakhs)\n",
    "    time.sleep(4)\n",
    "    salary_filter = driver.find_element_by_xpath('html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]/label/i')\n",
    "    salary_filter.click()  \n",
    "    time.sleep(4)\n",
    "    \n",
    "    \n",
    "    #so extarct all the tags having job-titles\n",
    "    title_tags = driver.find_elements_by_xpath(\"//a[@class= 'title fw500 ellipsis']\")\n",
    "    job_title_list = []   #creating a empty list\n",
    "    for i in title_tags[:10]:  #we only need 10 elements\n",
    "        job_title_list.append(i.text)   #appending it to the list\n",
    "    \n",
    "    #lets get all the company name\n",
    "    company_tags = driver.find_elements_by_xpath(\"//a[@class = 'subTitle ellipsis fleft']\")\n",
    "    company_list = []\n",
    "    for i in company_tags[:10]:\n",
    "        company_list.append(i.text)\n",
    "        \n",
    "    #lets extract the experice\n",
    "    #some data is missin in span tags, lets use parent tag li\n",
    "    experience_tags = driver.find_elements_by_xpath(\"//li[@class = 'fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "    experience_list = []\n",
    "    for i in experience_tags[:10]:\n",
    "        experience_list.append(i.text)\n",
    "    \n",
    "    #lets extract the loaction\n",
    "    #some data is missin in span tags, lets use parent tag li\n",
    "    location_tags = driver.find_elements_by_xpath(\"//li[@class = 'fleft grey-text br2 placeHolderLi location']//span\")\n",
    "    location_list = []\n",
    "    for i in location_tags[:10]:\n",
    "        location_list.append(i.text)\n",
    "\n",
    "    \n",
    "    \n",
    "    df_naukri['Job Title'] = job_title_list  #Creating a column for the particular list\n",
    "    df_naukri['Company'] = company_list\n",
    "    df_naukri['Experience'] = experience_list\n",
    "    df_naukri['Location'] = location_list\n",
    "    \n",
    " \n",
    "    return df_naukri  #returning the Dataframe as result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Excellent opportunity For Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Data Scientist - Noida/ B'lore</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Cloudstrats Technologies Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>BlackBuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mobikwik</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>New Delhi, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job Title  \\\n",
       "0  Data Scientist / Data Analyst -Business Analyst   \n",
       "1                                   Data Scientist   \n",
       "2         Excellent opportunity For Data Scientist   \n",
       "3                   Data Scientist - Noida/ B'lore   \n",
       "4                                   Data Scientist   \n",
       "5                                   Data Scientist   \n",
       "6                                   Data Scientist   \n",
       "7                                   Data Scientist   \n",
       "8         DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "9         DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "\n",
       "                                             Company Experience  \\\n",
       "0                 Inflexion Analytix Private Limited    0-3 Yrs   \n",
       "1                             IBM India Pvt. Limited    4-9 Yrs   \n",
       "2              NEC CORPORATION INDIA PRIVATE LIMITED    3-7 Yrs   \n",
       "3              NEC CORPORATION INDIA PRIVATE LIMITED    3-8 Yrs   \n",
       "4           Cloudstrats Technologies Private Limited    5-8 Yrs   \n",
       "5                                     Country Veggie    1-3 Yrs   \n",
       "6                                          BlackBuck    3-7 Yrs   \n",
       "7                                           Mobikwik    3-5 Yrs   \n",
       "8  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...    3-6 Yrs   \n",
       "9  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...    3-6 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "1  Noida, Hyderabad/Secunderabad, Bangalore/Benga...  \n",
       "2                         Noida, Bangalore/Bengaluru  \n",
       "3                         Noida, Bangalore/Bengaluru  \n",
       "4  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  \n",
       "5  Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpu...  \n",
       "6              Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "7           New Delhi, Gurgaon/Gurugram, Delhi / NCR  \n",
       "8                      Gurgaon/Gurugram, Delhi / NCR  \n",
       "9                      Gurgaon/Gurugram, Delhi / NCR  "
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the function to display the dataframe as result\n",
    "question3('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question4(url):\n",
    "    #activate chrome browser\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    #opening the homepage of amazon.in\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(4)\n",
    "    #We have sign in to this page first\n",
    "    \n",
    "    #it was asking signin evrytime, so i made it automated\n",
    "    #you can remove this part if not asking in your system\n",
    "    sign_in = driver.find_element_by_xpath(\"//button[@class= 'd-none d-lg-block p-0 LockedHomeHeaderStyles__signInButton']\")\n",
    "    time.sleep(4)\n",
    "    sign_in.click()  #sigining in\n",
    "    \n",
    "    \n",
    "    #providing the email\n",
    "    time.sleep(4)\n",
    "    Email  = driver.find_element_by_id(\"userEmail\")\n",
    "    Email.clear()\n",
    "    Email.send_keys('ullas1ga15cs167@gmail.com')\n",
    "    \n",
    "    #providing the password\n",
    "    password = driver.find_element_by_id('userPassword')\n",
    "    password.clear()\n",
    "    password.send_keys('Ullas#1234')\n",
    "    \n",
    "    #enter after providing both email and password\n",
    "    time.sleep(2)\n",
    "    password.send_keys(Keys.ENTER)\n",
    "    \n",
    "    #you can comment out the above steps if directly sigined in in your system\n",
    "    \n",
    "    #job title input\n",
    "    time.sleep(5)\n",
    "    job_title = driver.find_element_by_id('sc.keyword')\n",
    "    job_title.send_keys('Data scientist') #sending the key as Data scientist\n",
    "    \n",
    "    \n",
    "    #finding job job location input\n",
    "    time.sleep(4)\n",
    "    job_location = driver.find_element_by_id('sc.location')\n",
    "    time.sleep(4)\n",
    "    job_location.send_keys(Keys.CONTROL + \"a\")  #selecting if anything there in input box\n",
    "    time.sleep(2)\n",
    "    job_location.send_keys(Keys.DELETE)  #clearing the input\n",
    "    job_location.send_keys('Noida')  #send the key as noida\n",
    "    \n",
    "    time.sleep(2)\n",
    "    #search button\n",
    "    search_button = driver.find_element_by_xpath(\"//button[@class = 'gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "    search_button.click()  #clicking on search button\n",
    "    \n",
    "    \n",
    "    time.sleep(8)  #sometimes it will be very slow\n",
    "    \n",
    "    #company name\n",
    "    company_name = []\n",
    "    c_names = driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']/a/span\")\n",
    "    for i in c_names[:10]: #we need only ten elememts\n",
    "        company_name.append(i.text)  #appending it to the list\n",
    "        \n",
    "    #job titles\n",
    "    job_titles = []\n",
    "    j_titles = driver.find_elements_by_xpath(\"//a[@class='jobLink css-1rd3saf eigr9kq2']/span\")\n",
    "    for j in j_titles[:10]:\n",
    "        job_titles.append(j.text)\n",
    "    \n",
    "    \n",
    "    #how many days ago the job was posted\n",
    "    job_posted = []\n",
    "    j_posted = driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "    for k in j_posted[:10]:\n",
    "        job_posted.append(k.text)\n",
    "    \n",
    "    job_glassdoor_df = pd.DataFrame({})   #creating a empty dataframe\n",
    "    job_glassdoor_df['Company'] = company_name   #Creating a column for the particular list\n",
    "    job_glassdoor_df['Job Title'] =job_titles\n",
    "    job_glassdoor_df['job_posted'] = job_posted\n",
    "    \n",
    "    return job_glassdoor_df    #returning the Dataframe as result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>job_posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ericsson</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>8d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Techlive</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>Data Scientist - Gurgaon, HR</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>CRMNEXT</td>\n",
       "      <td>Data Scientist - Computer Vision</td>\n",
       "      <td>7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>WishFin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>CRMNEXT</td>\n",
       "      <td>Data Scientist – Voice &amp; NLP</td>\n",
       "      <td>7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>SearchUrCollege</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Company                         Job Title job_posted\n",
       "0                Biz2Credit Inc                    Data Scientist       30d+\n",
       "1                      Ericsson                    Data Scientist         8d\n",
       "2                      Techlive                    Data Scientist       30d+\n",
       "3  Salasar New Age Technologies                    Data Scientist       30d+\n",
       "4  Salasar New Age Technologies             Data Scientist Intern       30d+\n",
       "5            UnitedHealth Group      Data Scientist - Gurgaon, HR        24h\n",
       "6                       CRMNEXT  Data Scientist - Computer Vision         7d\n",
       "7                       WishFin                    Data Scientist       30d+\n",
       "8                       CRMNEXT      Data Scientist – Voice & NLP         7d\n",
       "9               SearchUrCollege                    Data Scientist       30d+"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the function to display the dataframe as result\n",
    "question4(' https://www.glassdoor.co.in/index.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question5(url):\n",
    "    #activate chrome browser\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    #opening the homepage of amazon.in\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    time.sleep(6) #sleep 6 seconds\n",
    "    job_title = driver.find_element_by_id('KeywordSearch')  #finding title input\n",
    "    job_title.send_keys('Data Scientist')   #sending input\n",
    "    \n",
    "    time.sleep(4)\n",
    "    job_location = driver.find_element_by_id('LocationSearch')  #finding location input\n",
    "    time.sleep(4)\n",
    "    job_location.send_keys(Keys.CONTROL + \"a\")  #clearing location flied\n",
    "    job_location.send_keys(Keys.DELETE)\n",
    "    job_location.send_keys('Noida')  #sending input\n",
    "    \n",
    "    time.sleep(2)\n",
    "    search_button = driver.find_element_by_id(\"HeroSearchButton\")  #seach button with id\n",
    "    search_button.click()  #clicking search button\n",
    "     \n",
    "    \n",
    "    time.sleep(6)\n",
    "    company_names = []   #creating a empty list\n",
    "    c_names = driver.find_elements_by_xpath(\"//div[@class='d-flex']/div[2]/p[2]\")\n",
    "    for i in c_names[:10]:  #since we need only 10\n",
    "        company_names.append(i.text)  #appending it to the list\n",
    "    \n",
    "    average_salary = []\n",
    "    #creating xpath associated with the output required\n",
    "    a_salary = driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")\n",
    "    for j in a_salary[:10]:\n",
    "        average_salary.append(j.text)\n",
    "    \n",
    "    minimum_salary = []\n",
    "    min_salary = driver.find_elements_by_xpath(\"//div[@class = 'common__RangeBarStyle__values d-flex justify-content-between ']/span[1]\")\n",
    "    for k in min_salary[:10]:\n",
    "        minimum_salary.append(k.text)\n",
    "   \n",
    "    maximum_salary = []\n",
    "    max_salary = driver.find_elements_by_xpath(\"//div[@class = 'common__RangeBarStyle__values d-flex justify-content-between ']/span[2]\")\n",
    "    for l in max_salary[:10]:\n",
    "        maximum_salary.append(l.text)\n",
    "        \n",
    "    salary_df = pd.DataFrame({})   #creating a empty dataframe\n",
    "    \n",
    "    salary_df[\"Company\"] = company_names  #Creating a column for the particular list\n",
    "    salary_df[\"Average Salary\"] =average_salary\n",
    "    salary_df['Minimum Salary'] = minimum_salary\n",
    "    salary_df['Maximum Salary'] = maximum_salary\n",
    "    \n",
    "    return salary_df  #returning the Dataframe as result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹ 6,11,228</td>\n",
       "      <td>₹343K</td>\n",
       "      <td>₹1,095K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹ 11,46,533</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,213K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>IBM</td>\n",
       "      <td>₹ 8,97,795</td>\n",
       "      <td>₹586K</td>\n",
       "      <td>₹2,730K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹ 7,38,057</td>\n",
       "      <td>₹355K</td>\n",
       "      <td>₹1,613K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹ 12,39,781</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,622K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹ 13,36,142</td>\n",
       "      <td>₹1,069K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹ 8,15,192</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,465K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹ 11,35,221</td>\n",
       "      <td>₹202K</td>\n",
       "      <td>₹1,809K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹ 11,44,243</td>\n",
       "      <td>₹575K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹ 14,13,288</td>\n",
       "      <td>₹1,014K</td>\n",
       "      <td>₹2,149K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company Average Salary Minimum Salary Maximum Salary\n",
       "0  Tata Consultancy Services     ₹ 6,11,228          ₹343K        ₹1,095K\n",
       "1                  Accenture    ₹ 11,46,533          ₹577K        ₹2,213K\n",
       "2                        IBM     ₹ 8,97,795          ₹586K        ₹2,730K\n",
       "3         Ericsson-Worldwide     ₹ 7,38,057          ₹355K        ₹1,613K\n",
       "4                  Delhivery    ₹ 12,39,781          ₹450K       ₹11,622K\n",
       "5         UnitedHealth Group    ₹ 13,36,142        ₹1,069K        ₹1,520K\n",
       "6         Valiance Solutions     ₹ 8,15,192          ₹502K        ₹1,465K\n",
       "7              ZS Associates    ₹ 11,35,221          ₹202K        ₹1,809K\n",
       "8                EXL Service    ₹ 11,44,243          ₹575K        ₹1,520K\n",
       "9     Optum Global Solutions    ₹ 14,13,288        ₹1,014K        ₹2,149K"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the function to display the dataframe as result\n",
    "question5('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and\n",
    "more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page\n",
    "you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of\n",
    "the page , then click on it\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses.\n",
    "Note that all of the above steps have to be done by coding only and not manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question6(url):\n",
    "    \n",
    "    #activate chrome browser\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    \n",
    "    #opening the flipcart.com\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    #we can skip the login option by closing the popup\n",
    "    #because i am getting loh=gin option everytime\n",
    "    #if you are getting login popup, please comment out the below three lines\n",
    "    time.sleep(4)\n",
    "    skip_login = driver.find_element_by_xpath(\"//button[@class ='_2KpZ6l _2doB4z']\")\n",
    "    skip_login.click()\n",
    "    \n",
    "    time.sleep(4)\n",
    "    #finding the element for product search bar\n",
    "    product_search = driver.find_element_by_xpath(\"//div[@class = '_3OO5Xc']/input\")\n",
    "    #write on search bar\n",
    "    product_search.send_keys(\"sunglasses\")\n",
    "    \n",
    "    \n",
    "    #finding the search button with xpath\n",
    "    search =driver.find_element_by_xpath(\"//button[@class = 'L0Z3Pu']\") \n",
    "    search.click()  #clicking the button\n",
    "    \n",
    "    SG_names = []\n",
    "    SG_price = []\n",
    "    SG_desc = []\n",
    "    SG_discount = []\n",
    "    \n",
    "    x = 0\n",
    "    while len(SG_names) < 100:\n",
    "        \n",
    "    \n",
    "        time.sleep(5)\n",
    "        #finding the name of sunglasses\n",
    "\n",
    "        name = driver.find_elements_by_xpath(\"//div[@class= '_2WkVRV']\")   #finding the Xpath associated with particular class\n",
    "        for i in name:\n",
    "            SG_names.append(i.text)   #appending it to the list\n",
    "\n",
    "        #finding the name of sunglasses\n",
    "        price = driver.find_elements_by_xpath(\"//div[@class= '_30jeq3']\")\n",
    "        for j in price:\n",
    "            SG_price.append(j.text)  \n",
    "\n",
    "        #finding the product description of sunglasses\n",
    "        desc = driver.find_elements_by_xpath(\"//div[@class= '_2B099V']/a[1]\")\n",
    "        for k in desc:\n",
    "            SG_desc.append(k.text)\n",
    "\n",
    "        #finding the discount of sunglasses\n",
    "        \n",
    "        discount = driver.find_elements_by_xpath(\"//div[@class= '_3Ay6Sb']/span\")\n",
    "        for l in discount:\n",
    "            SG_discount.append(l.text)\n",
    "        \n",
    "        #navigating to the next page\n",
    "        if x == 0:\n",
    "            Next_page = driver.find_element_by_xpath(\"//a[@class= '_1LKTO3']/span\")  #xpath will get changed form 2nd page\n",
    "            Next_page.click()   #clicking next\n",
    "        else:\n",
    "            Next_page = driver.find_element_by_xpath(\"//nav[@class= 'yFHi8N']/a[12]/span\")\n",
    "            Next_page.click()\n",
    "            \n",
    "        x += 1   # counter\n",
    "    \n",
    "    sunglasses_df = pd.DataFrame({})   #creating a empty dataframe\n",
    "    \n",
    "    sunglasses_df['Brand'] = SG_names[:100]  #since we need only 100 product details\n",
    "    sunglasses_df['Price'] = SG_price[:100]\n",
    "    sunglasses_df['Discount'] = SG_discount[:100]\n",
    "    sunglasses_df['Description'] = SG_desc[:100]\n",
    "\n",
    "    return sunglasses_df   #returning the Dataframe as result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>hipe</td>\n",
       "      <td>₹219</td>\n",
       "      <td>78% off</td>\n",
       "      <td>Mirrored Wayfarer Sunglasses (55)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>hipe</td>\n",
       "      <td>₹210</td>\n",
       "      <td>85% off</td>\n",
       "      <td>Mirrored, UV Protection, Gradient Round Sungla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹250</td>\n",
       "      <td>84% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹630</td>\n",
       "      <td>21% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>hipe</td>\n",
       "      <td>₹210</td>\n",
       "      <td>83% off</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses, G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>hipe</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>GANSTA</td>\n",
       "      <td>₹224</td>\n",
       "      <td>77% off</td>\n",
       "      <td>UV Protection, Mirrored Wayfarer Sunglasses (53)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>₹255</td>\n",
       "      <td>78% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (62)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>AISLIN</td>\n",
       "      <td>₹440</td>\n",
       "      <td>76% off</td>\n",
       "      <td>UV Protection, Mirrored Shield, Wayfarer Sungl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand Price Discount  \\\n",
       "0           hipe  ₹219  78% off   \n",
       "1           hipe  ₹210  85% off   \n",
       "2         PIRASO  ₹250  84% off   \n",
       "3       Fastrack  ₹758  15% off   \n",
       "4       Fastrack  ₹630  21% off   \n",
       "..           ...   ...      ...   \n",
       "95          hipe  ₹210  83% off   \n",
       "96          hipe  ₹199  80% off   \n",
       "97        GANSTA  ₹224  77% off   \n",
       "98  Silver Kartz  ₹255  78% off   \n",
       "99        AISLIN  ₹440  76% off   \n",
       "\n",
       "                                          Description  \n",
       "0                   Mirrored Wayfarer Sunglasses (55)  \n",
       "1   Mirrored, UV Protection, Gradient Round Sungla...  \n",
       "2               UV Protection Aviator Sunglasses (54)  \n",
       "3       UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "4    UV Protection Rectangular Sunglasses (Free Size)  \n",
       "..                                                ...  \n",
       "95  UV Protection, Night Vision, Riding Glasses, G...  \n",
       "96      UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "97   UV Protection, Mirrored Wayfarer Sunglasses (53)  \n",
       "98              UV Protection Aviator Sunglasses (62)  \n",
       "99  UV Protection, Mirrored Shield, Wayfarer Sungl...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the function to display the dataframe as result\n",
    "question6('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question7(url):\n",
    "    \n",
    "    #activate chrome browser\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    \n",
    "    #opening the flipcart.com\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    #all review button\n",
    "    time.sleep(5)\n",
    "    All_review = driver.find_element_by_xpath(\"//div[@class = '_3UAT2v _16PBlm']/span\")\n",
    "    All_review.click()\n",
    "    \n",
    "    \n",
    "    #finding the ratings of all iphones\n",
    "    iphone_rating = []     #returning the list\n",
    "    iphone_summary = []\n",
    "    iphone_review = []\n",
    "    x = 0\n",
    "    while len(iphone_rating) < 100:  #stopping the while loop at 100 \n",
    "\n",
    "        time.sleep(4)   #sleep 4 seconds after every loop\n",
    "         \n",
    "        #Rating provided by the user\n",
    "        #finding the tag associated with particular class\n",
    "        i_rating = driver.find_elements_by_xpath(\"//div[@class = 'col _2wzgFH K0kLPL']/div[1]/div\")\n",
    "        for i in i_rating:\n",
    "            iphone_rating.append(i.text)  #appending it to the list\n",
    "        \n",
    "        #summary provided by the user\n",
    "        i_summary = driver.find_elements_by_xpath(\"//div[@class = 'col _2wzgFH K0kLPL']/div[1]/p\")\n",
    "        for j in i_summary:\n",
    "            iphone_summary.append(j.text)\n",
    "            \n",
    "        #review provided by the user\n",
    "        i_review = driver.find_elements_by_xpath(\"//div[@class = 't-ZTKy']/div/div\")\n",
    "        for k in i_review:\n",
    "            iphone_review.append(k.text)\n",
    "\n",
    "        if x == 0:\n",
    "            #next button in first page\n",
    "            time.sleep(1)\n",
    "            next_button_p1 = driver.find_element_by_xpath(\"//a[@class = '_1LKTO3']/span\")  #xpath will get changed form 2nd page\n",
    "            next_button_p1.click()\n",
    "        else:\n",
    "            #next button from second page\n",
    "            next_button = driver.find_element_by_xpath(\"//nav[@class = 'yFHi8N']/a[12]/span\")\n",
    "            next_button.click()\n",
    "            x += 1\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    iphone_df = pd.DataFrame({})   #creating a empty dataframe\n",
    "    \n",
    "    iphone_df['Rating'] = iphone_rating[:100]  #since we need only 100 product details\n",
    "    iphone_df['Summary'] = iphone_summary[:100]\n",
    "    iphone_df['Review'] = iphone_review[:100]\n",
    "\n",
    "    return iphone_df   #returning the Dataframe as result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Really worth of money. i just love it. It is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is my first ever I phone. Before this I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Superb Product !!!\\nA big and worthy upgrade f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>I have migrated from OP 7pro... and trust me, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating             Summary  \\\n",
       "0       5           Brilliant   \n",
       "1       5    Perfect product!   \n",
       "2       4         Good choice   \n",
       "3       5       Great product   \n",
       "4       5   Worth every penny   \n",
       "..    ...                 ...   \n",
       "95      5            Terrific   \n",
       "96      5  Highly recommended   \n",
       "97      5           Wonderful   \n",
       "98      5      Classy product   \n",
       "99      5           Brilliant   \n",
       "\n",
       "                                               Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   So far it’s been an AMAZING experience coming ...  \n",
       "3   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  Really worth of money. i just love it. It is t...  \n",
       "96  It's my first time to use iOS phone and I am l...  \n",
       "97  This is my first ever I phone. Before this I w...  \n",
       "98  Superb Product !!!\\nA big and worthy upgrade f...  \n",
       "99  I have migrated from OP 7pro... and trust me, ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the function to display the dataframe as result\n",
    "question7('https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "\n",
    "#run try it again if you get the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question8(url):\n",
    "    \n",
    "    #activate chrome browser\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    #opening the flipcart.com\n",
    "    driver.get('https://www.flipkart.com/')\n",
    "    \n",
    "    time.sleep(3)\n",
    "    skip_login = driver.find_element_by_xpath(\"//button[@class ='_2KpZ6l _2doB4z']\")\n",
    "    skip_login.click()\n",
    "    \n",
    "    #finding the element for product search bar\n",
    "    product_search = driver.find_element_by_xpath(\"//div[@class = '_3OO5Xc']/input\")\n",
    "    #write on search bar\n",
    "    product_search.send_keys(\"sneakers\")\n",
    "    \n",
    "    #finding the search button with xpath\n",
    "    search =driver.find_element_by_xpath(\"//button[@class = 'L0Z3Pu']\") \n",
    "    search.click()  #clicking the button\n",
    "\n",
    "\n",
    "    #finding the tag associated with particular class\n",
    "    shoe_brand = []\n",
    "    shoe_desc = []\n",
    "    shoe_price = []\n",
    "    shoe_discount = []\n",
    "    x =0\n",
    "\n",
    "    while len(shoe_brand) < 100:\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        brand = driver.find_elements_by_xpath(\"//div[@class = '_2WkVRV']\")\n",
    "        for i in brand:\n",
    "            shoe_brand.append(i.text)  #appending it to the list\n",
    "\n",
    "        desc = driver.find_elements_by_xpath(\"//div[@class = '_2B099V']/a[1]\")\n",
    "        for j in desc:\n",
    "            shoe_desc.append(j.text)\n",
    "\n",
    "        price = driver.find_elements_by_xpath(\"//div[@class = '_30jeq3']\")\n",
    "        for k in price:\n",
    "            shoe_price.append(k.text)\n",
    "\n",
    "        discount = driver.find_elements_by_xpath(\"//div[@class = '_3Ay6Sb']/span\")\n",
    "        for l in discount:\n",
    "            shoe_discount.append(l.text)\n",
    "\n",
    "        if x == 0:\n",
    "            #next button in first page\n",
    "            next_button_p1 = driver.find_element_by_xpath(\"//a[@class = '_1LKTO3']/span\")  #xpath will get changed form 2nd page\n",
    "            next_button_p1.click()\n",
    "        else:\n",
    "            #next button from second page\n",
    "            next_button = driver.find_element_by_xpath(\"//nav[@class = 'yFHi8N']/a[12]/span\")\n",
    "            next_button.click()\n",
    "\n",
    "        x += 1\n",
    "\n",
    "\n",
    "    sneakers_df = pd.DataFrame({})   #creating a empty dataframe\n",
    "\n",
    "    sneakers_df['Brand'] = shoe_brand[:100]  #since we need only 100 product details\n",
    "    sneakers_df['Description'] = shoe_desc[:100]\n",
    "    sneakers_df['Price'] = shoe_price[:100]\n",
    "    sneakers_df['Discount'] = shoe_discount[:100]\n",
    "\n",
    "    return sneakers_df  #returning the Dataframe as result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>well feet</td>\n",
       "      <td>sneaker for mens and boys Sneakers For Men</td>\n",
       "      <td>₹429</td>\n",
       "      <td>28% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Bucik</td>\n",
       "      <td>Multicolor Casual Shoes Mesh for Men Sneakers ...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹298</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>JUBENTA</td>\n",
       "      <td>Latest Design Sneakers For Men</td>\n",
       "      <td>₹549</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>Adiso</td>\n",
       "      <td>Casual sneakers,outdoors,dancingshoes Sneakers...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>48% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>India hub</td>\n",
       "      <td>Fashionable casual sneakers shoes Sneakers For...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>VISTAARA</td>\n",
       "      <td>349 Red Sneakers For Men</td>\n",
       "      <td>₹259</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                        Description Price  \\\n",
       "0      well feet         sneaker for mens and boys Sneakers For Men  ₹429   \n",
       "1          Bucik  Multicolor Casual Shoes Mesh for Men Sneakers ...  ₹599   \n",
       "2   Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men  ₹399   \n",
       "3           aadi                                   Sneakers For Men  ₹298   \n",
       "4        Numenzo                                   Sneakers For Men  ₹398   \n",
       "..           ...                                                ...   ...   \n",
       "95       JUBENTA                     Latest Design Sneakers For Men  ₹549   \n",
       "96     ROCKFIELD                                   Sneakers For Men  ₹399   \n",
       "97         Adiso  Casual sneakers,outdoors,dancingshoes Sneakers...  ₹399   \n",
       "98     India hub  Fashionable casual sneakers shoes Sneakers For...  ₹449   \n",
       "99      VISTAARA                           349 Red Sneakers For Men  ₹259   \n",
       "\n",
       "   Discount  \n",
       "0   28% off  \n",
       "1   70% off  \n",
       "2   60% off  \n",
       "3   70% off  \n",
       "4   60% off  \n",
       "..      ...  \n",
       "95  60% off  \n",
       "96  82% off  \n",
       "97  48% off  \n",
       "98  50% off  \n",
       "99  77% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the function to display the dataframe as result\n",
    "question8('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of\n",
    "the shoes , Short Shoe description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question9(url):\n",
    "    #activate chrome browser\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    #opening the myntra.com\n",
    "    driver.get(url)\n",
    "    \n",
    "    #finding price filter range 6k - 13 k\n",
    "    time.sleep(8)\n",
    "    price_filter = driver.find_element_by_xpath(\"//ul[@class = 'price-list']/li[2]/label/div\")\n",
    "    price_filter.click()\n",
    "    \n",
    "    #finding color filter black\n",
    "    time.sleep(6)\n",
    "    color_filter = driver.find_element_by_xpath(\"//li[@class = 'colour-listItem'][1]/label/div\")\n",
    "    color_filter.click()\n",
    "    \n",
    "    s_brand_list = []   #creating a empty list\n",
    "    s_desc_list = []\n",
    "    s_price_list = []\n",
    "    \n",
    "    while len(s_brand_list) < 100:  #breaking while loop when 100 is reached\n",
    "        \n",
    "        time.sleep(5) #sleep for 5 seconds after every loop\n",
    "        \n",
    "        #Find the brand name\n",
    "        s_brand = driver.find_elements_by_xpath(\"//div[@class = 'product-productMetaInfo']/h3\")\n",
    "        for i in s_brand:\n",
    "            s_brand_list.append(i.text)\n",
    "        len(s_brand_list)\n",
    "\n",
    "        #Finding the description\n",
    "\n",
    "        s_desc = driver.find_elements_by_xpath(\"//div[@class = 'product-productMetaInfo']/h4[1]\")\n",
    "        for j in s_desc:\n",
    "            s_desc_list.append(j.text)\n",
    "        len(s_desc_list)\n",
    "\n",
    "        #Finding the price\n",
    "\n",
    "        s_price = driver.find_elements_by_xpath(\"//div[@class = 'product-productMetaInfo']/div[1]/span[1]\")\n",
    "        for k in s_price:\n",
    "            price = k.text[:9].replace('R','')  #some div tags have only one and some have two so have to do this\n",
    "            a = 'R'+price\n",
    "            s_price_list.append(a)\n",
    "        len(s_price_list)\n",
    "\n",
    "        #next button \n",
    "        next_button = driver.find_element_by_xpath(\"//li[@class = 'pagination-next']/a\")\n",
    "        next_button.click()\n",
    "        \n",
    "    myntra_shoe_df = pd.DataFrame({})   #creating a empty dataframe\n",
    "    \n",
    "    myntra_shoe_df['Brand'] = s_brand_list[:100]   #Creating a column for the particular list since we need only 100\n",
    "    myntra_shoe_df['Price'] = s_price_list[:100]\n",
    "    myntra_shoe_df['Description'] = s_desc_list[:100]\n",
    "    \n",
    "    return myntra_shoe_df   #returning the Dataframe as result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 10846</td>\n",
       "      <td>Men React Infinity Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 11495</td>\n",
       "      <td>AIR ZOOM PEGASUS Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 12495</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>Unisex Mercedes Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 9999</td>\n",
       "      <td>Unisex RS-FAST TECH Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Rs. 12749</td>\n",
       "      <td>Men Ultraboost DNA CC_1 Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 8396</td>\n",
       "      <td>Men REACT PHANTOM FLYKNIT2 Run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 9371</td>\n",
       "      <td>Men REACT MILER PRM Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Rs. 7999</td>\n",
       "      <td>Men Slip-On Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Rs. 8990</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand      Price                      Description\n",
       "0              Nike  Rs. 10846       Men React Infinity Running\n",
       "1              Nike  Rs. 11495   AIR ZOOM PEGASUS Running Shoes\n",
       "2              Nike  Rs. 12495      Men JORDAN DELTA Basketball\n",
       "3   PUMA Motorsport   Rs. 7999    Unisex Mercedes Running Shoes\n",
       "4              Puma   Rs. 9999     Unisex RS-FAST TECH Sneakers\n",
       "..              ...        ...                              ...\n",
       "95           ADIDAS  Rs. 12749    Men Ultraboost DNA CC_1 Shoes\n",
       "96             Nike   Rs. 8396   Men REACT PHANTOM FLYKNIT2 Run\n",
       "97             Nike   Rs. 9371      Men REACT MILER PRM Running\n",
       "98          Bugatti   Rs. 7999             Men Slip-On Sneakers\n",
       "99            Ruosh   Rs. 8990  Men Solid Leather Formal Derbys\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the function to display the dataframe as result\n",
    "question9('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qusetion 10"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "    \n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Question10(url):\n",
    "    #activate chrome browser\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    #opening the amazon.com\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    #finding the element for product search bar\n",
    "    Laptop_search = driver.find_element_by_xpath(\"//div[@class='nav-search-field ']/input\")\n",
    "    #write on search bar\n",
    "    Laptop_search.send_keys(\"Laptop\")\n",
    "    \n",
    "    search_key = driver.find_element_by_id('nav-search-submit-button')\n",
    "    search_key.click()\n",
    "    \n",
    "    \n",
    "    #filter\n",
    "    time.sleep(4)\n",
    "    i7 = driver.find_element_by_xpath(\"//li[@id = 'p_n_feature_thirteen_browse-bin/12598163031']/span/a\")\n",
    "    i7.click()\n",
    "    #we can't choose two processors i7 and i9 , because the page allows only one\n",
    "    \n",
    "    time.sleep(4)\n",
    "    #lets create the list of first 10 links of laaptp after filter\n",
    "    links_list = []\n",
    "    links = driver.find_elements_by_xpath(\"//a[@class = 'a-link-normal a-text-normal']\")\n",
    "    for i in links[:10]:\n",
    "        links_list.append(i.get_attribute('href')) #appendinf links\n",
    "\n",
    "        \n",
    "        \n",
    "    name_list = []  #creating empty lists\n",
    "    price_list = []\n",
    "    rating_list = []\n",
    "    for k in links_list:\n",
    "        driver.get(k)  #getting lists one by one\n",
    "        time.sleep(5)\n",
    "\n",
    "        #name\n",
    "        name = driver.find_element_by_xpath(\"//h1[@id = 'title']\")    #getting name\n",
    "        name_list.append(name.text)\n",
    "\n",
    "        #price\n",
    "        #price is not given for out of stock items or brand new items, so using exception handling\n",
    "        try:\n",
    "            price = driver.find_element_by_xpath(\"//span[@id = 'priceblock_ourprice']\")\n",
    "        except NoSuchElementException:\n",
    "            price_list.append(\"Out of stcok, Price not available\")\n",
    "        else:\n",
    "            price_list.append(price.text)\n",
    "\n",
    "\n",
    "\n",
    "        #ratings\n",
    "        #For some new laptops rating are not given, so lets use exception handlings\n",
    "        try:\n",
    "            review_link = driver.find_element_by_xpath(\"//span[@id = 'acrCustomerReviewText']\")\n",
    "        except NoSuchElementException:\n",
    "            rating_list.append(\"Review Not Given\")\n",
    "        else:\n",
    "            review_link.click()\n",
    "            time.sleep(3)\n",
    "            rating = driver.find_element_by_xpath(\"//span[@class =  'a-size-base a-nowrap']/span\")\n",
    "            rating_list.append(rating.text)\n",
    "\n",
    "    \n",
    "    \n",
    "    laptop_df = pd.DataFrame({})    #creating a empty dataframe\n",
    "    laptop_df['Name'] = name_list  #we need ony 10\n",
    "    laptop_df['Price'] = price_list\n",
    "    laptop_df['Rating'] = rating_list\n",
    "    \n",
    "    return laptop_df    #returning the Dataframe as result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(Renewed) Dell Latitude E6420 14 Inch Laptop (...</td>\n",
       "      <td>₹ 34,000.00</td>\n",
       "      <td>Review Not Given</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(Renewed) Lenovo T430 14-inch Laptop (Core i7/...</td>\n",
       "      <td>₹ 53,499.00</td>\n",
       "      <td>Review Not Given</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(Renewed) Lenovo T430 14-inch Laptop (Core i7/...</td>\n",
       "      <td>₹ 37,499.00</td>\n",
       "      <td>Review Not Given</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(Renewed) Lenovo T430 14-inch Laptop (Core i7/...</td>\n",
       "      <td>₹ 37,999.00</td>\n",
       "      <td>Review Not Given</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(Renewed) Lenovo Intel 4th Gen Core i7-4980HQ ...</td>\n",
       "      <td>₹ 46,290.00</td>\n",
       "      <td>3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7...</td>\n",
       "      <td>₹ 84,200.00</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>HP 14 Thin &amp; Light 14\" (35.56cms) FHD Laptop (...</td>\n",
       "      <td>Out of stcok, Price not available</td>\n",
       "      <td>4.7 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...</td>\n",
       "      <td>₹ 3,43,099.00</td>\n",
       "      <td>5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>(Renewed) Dell Intel 6th Gen Core i7-6820HQ 15...</td>\n",
       "      <td>₹ 61,799.00</td>\n",
       "      <td>Review Not Given</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>(Renewed) Dell Latitude E7470 14-inch Laptop (...</td>\n",
       "      <td>₹ 65,299.00</td>\n",
       "      <td>Review Not Given</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0  (Renewed) Dell Latitude E6420 14 Inch Laptop (...   \n",
       "1  (Renewed) Lenovo T430 14-inch Laptop (Core i7/...   \n",
       "2  (Renewed) Lenovo T430 14-inch Laptop (Core i7/...   \n",
       "3  (Renewed) Lenovo T430 14-inch Laptop (Core i7/...   \n",
       "4  (Renewed) Lenovo Intel 4th Gen Core i7-4980HQ ...   \n",
       "5  Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7...   \n",
       "6  HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (...   \n",
       "7  Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...   \n",
       "8  (Renewed) Dell Intel 6th Gen Core i7-6820HQ 15...   \n",
       "9  (Renewed) Dell Latitude E7470 14-inch Laptop (...   \n",
       "\n",
       "                               Price            Rating  \n",
       "0                        ₹ 34,000.00  Review Not Given  \n",
       "1                        ₹ 53,499.00  Review Not Given  \n",
       "2                        ₹ 37,499.00  Review Not Given  \n",
       "3                        ₹ 37,999.00  Review Not Given  \n",
       "4                        ₹ 46,290.00        3 out of 5  \n",
       "5                        ₹ 84,200.00      4.3 out of 5  \n",
       "6  Out of stcok, Price not available      4.7 out of 5  \n",
       "7                      ₹ 3,43,099.00        5 out of 5  \n",
       "8                        ₹ 61,799.00  Review Not Given  \n",
       "9                        ₹ 65,299.00  Review Not Given  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the function to display the dataframe as result\n",
    "Question10('https://www.amazon.in/')\n",
    "\n",
    "#i am not able retrieve rataings from this webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
